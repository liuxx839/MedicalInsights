import streamlit as st
import re
import time
from PIL import Image
from utils import match_color, determine_issue_severity, create_json_data
from config import json_to_dataframe, get_rewrite_system_message, colors, topics, primary_topics_list
from streamlit_extras.stylable_container import stylable_container
from groq import Groq
from zhipuai import ZhipuAI
import os
import base64
from io import BytesIO
import numpy as np
import pickle
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

# api_key = os.environ.get("GROQ_API_KEY")
# client = Groq(api_key=api_key)
api_key_vision = os.environ.get("ZHIPU_API_KEY")
client_vision = ZhipuAI(api_key=api_key_vision)

## Load embedding model
# @st.cache_resource
# def load_embedding_model():
#     return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

@st.cache_resource
def load_embedding_model():
    return ZhipuAI(api_key=api_key_vision)

# @st.cache_resource
# def load_embedding_model():
#     # Use local model directory instead of downloading from HuggingFace
#     local_model_path = './embed_models/sentence-transformer'
#     try:
#         return SentenceTransformer(local_model_path)
#     except Exception as e:
#         st.error(f"Error loading model from {local_model_path}: {str(e)}")
#         return None
        
# Load embeddings from pkl file
@st.cache_data
def load_embeddings():
    try:
        with open('medical_text_embeddings_zhipu_256_250305.pkl', 'rb') as f:
            return pickle.load(f)
    except FileNotFoundError:
        st.error("Embeddings file not found. Please make sure 'embeddings.pkl' exists in the current directory.")
        return None

# def get_color(similarity):
#     if similarity >= 0.8:
#         return "#067647"  # ç»¿è‰²
#     elif similarity >= 0.6:
#         return "#B42318"  # çº¢è‰²
#     elif similarity >= 0.4:
#         return "#B54708"  # æ£•è‰²
#     elif similarity >= 0.2:
#         return "#175CD3"  # è“è‰²
#     elif similarity >= 0.1:
#         return "#282828"  # é»‘è‰²
#     else:
#         return "#7A00E6"  # ç´«è‰²
# def get_similar_content(user_input, embeddings_data, model, top_k=5):
#     """
#     Find top-k similar content based on embeddings
    
#     Args:
#         user_input (str): User input text
#         embeddings_data (dict): Dictionary with embeddings and content
#         model: SentenceTransformer model
#         top_k (int): Number of similar contents to return
        
#     Returns:
#         list: List of top-k similar contents
#     """
#     if embeddings_data is None or user_input.strip() == "":
#         return []
    
#     # Get embeddings for user input
#     user_embedding = model.encode([user_input])[0].reshape(1, -1)
    
#     # Get all stored embeddings
#     stored_embeddings = np.array(embeddings_data['embeddings'])
#     stored_contents = embeddings_data['contents']
    
#     # Calculate similarity
#     similarities = cosine_similarity(user_embedding, stored_embeddings)[0]
    
#     # Get indices of top-k similar contents
#     top_indices = similarities.argsort()[-top_k:][::-1]
    
#     # Return top-k similar contents with their similarity scores
#     similar_contents = [
#         {"content": stored_contents[idx], "similarity": similarities[idx]}
#         for idx in top_indices
#     ]
    
#     return similar_contents

# def get_similar_content(user_input, embeddings_data, model, top_k=5):
#     """
#     Find top-k similar content based on embeddings
    
#     Args:
#         user_input (str): User input text
#         embeddings_data (dict): Dictionary with embeddings and content
#         model: SentenceTransformer model
#         top_k (int): Number of similar contents to return
        
#     Returns:
#         list: List of top-k similar contents
#     """
#     if embeddings_data is None or user_input.strip() == "":
#         return []
    
#     # Get embeddings for user input
#     user_embedding = model.encode([user_input])[0].reshape(1, -1)
    
#     # Get all stored embeddings
#     stored_embeddings = np.array(embeddings_data['embeddings'])
#     stored_contents = embeddings_data['contents']
    
#     # Check if timestamps are available
#     has_timestamps = 'timestamps' in embeddings_data
    
#     # Calculate similarity
#     similarities = cosine_similarity(user_embedding, stored_embeddings)[0]
    
#     # Get indices of top-k similar contents
#     top_indices = similarities.argsort()[-top_k:][::-1]
    
#     # Return top-k similar contents with their similarity scores and timestamps if available
#     similar_contents = []
#     for idx in top_indices:
#         item = {
#             "content": stored_contents[idx],
#             "similarity": similarities[idx]
#         }
        
#         # Add timestamp if available
#         if has_timestamps:
#             item["timestamp"] = embeddings_data['timestamps'][idx]
            
#         similar_contents.append(item)
    
#     return similar_contents

def get_similar_content(user_input, embeddings_data, client, top_k=5):
    """
    Find top-k similar content based on embeddings
    
    Args:
        user_input (str): User input text
        embeddings_data (dict): Dictionary with embeddings and content
        client: ZhipuAI client
        top_k (int): Number of similar contents to return
        
    Returns:
        list: List of top-k similar contents
    """
    if embeddings_data is None or user_input.strip() == "":
        return []
    
    # Get embeddings for user input
    response = client.embeddings.create(
        model="embedding-3",
        input=[user_input],
        dimensions=256
    )
    user_embedding = np.array(response.data[0].embedding).reshape(1, -1)
    
    # Get all stored embeddings
    stored_embeddings = np.array(embeddings_data['embeddings'])
    stored_contents = embeddings_data['contents']
    
    # Check if timestamps are available
    has_timestamps = 'timestamps' in embeddings_data
    
    # Calculate similarity
    similarities = cosine_similarity(user_embedding, stored_embeddings)[0]
    
    # Get indices of top-k similar contents
    top_indices = similarities.argsort()[-top_k:][::-1]
    
    # Return top-k similar contents with their similarity scores and timestamps if available
    similar_contents = []
    for idx in top_indices:
        item = {
            "content": stored_contents[idx],
            "similarity": similarities[idx]
        }
        
        # Add timestamp if available
        if has_timestamps:
            item["timestamp"] = embeddings_data['timestamps'][idx]
            
        similar_contents.append(item)
    
    return similar_contents

def encode_image(image):
    """
    Encode a PIL Image object to a Base64 string with compression and ensure it is under 4MB.
    """
    max_size = (800, 800)  # è®¾ç½®æœ€å¤§å°ºå¯¸
    max_file_size = 4 * 1024 * 1024  # 4MB æ–‡ä»¶å¤§å°é™åˆ¶
    
    # å‹ç¼©å›¾ç‰‡
    image.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå»é™¤alphaé€šé“ï¼‰
    if image.mode in ('RGBA', 'LA'):
        background = Image.new('RGB', image.size, (255, 255, 255))
        background.paste(image, mask=image.split()[-1])
        image = background
    
    # å°è¯•é™ä½è´¨é‡ï¼Œç›´åˆ°å›¾åƒæ–‡ä»¶å¤§å°å°äº 4MB
    quality = 95  # åˆå§‹è´¨é‡ä¸º95
    buffered = BytesIO()
    
    # åå¤å‹ç¼©ç›´åˆ°æ–‡ä»¶å¤§å°å°äº4MB
    while True:
        buffered.seek(0)
        image.save(buffered, format="JPEG", quality=quality, optimize=True)
        
        # å¦‚æœæ–‡ä»¶å¤§å°å°äº4MBï¼Œè·³å‡ºå¾ªç¯
        if len(buffered.getvalue()) <= max_file_size:
            break
        
        # æ¯æ¬¡é™ä½5%çš„è´¨é‡
        quality -= 5
    
    # è¿”å›Base64ç¼–ç 
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def readimg(user_image):
    """
    Process a PIL Image and extract text using Groq's vision model.
    """
    if client_vision is None:
        raise ValueError("Groq client must be provided")

    try:
        # å¤åˆ¶å›¾ç‰‡å¯¹è±¡ä»¥é¿å…ä¿®æ”¹åŸå§‹å›¾ç‰‡
        image_to_process = user_image.copy()
        base64_image = encode_image(image_to_process)
        
        response = client_vision.chat.completions.create(
            model="glm-4v-plus",  # Fill in the model name to be called
            messages=[
              {
                "role": "user",
                "content": [
                  {
                    "type": "image_url",
                    "image_url": {
                        "url": base64_image
                    }
                  },
                  {
                    "type": "text",
                    "text": "æå–å›¾ç‰‡é‡Œçš„æ–‡å­—"
                  }
                ]
              }
            ]
        )
        return(response.choices[0].message.content)

    except Exception as e:
        raise Exception(f"Error processing image with Groq API: {str(e)}")


def setup_layout(
    topics, diseases, institutions, departments, persons,
    primary_topics_list, primary_diseases_list,
    generate_tag, generate_diseases_tag, rewrite,
    prob_identy, generate_structure_data,
    model_choice, client
):
    # Load embedding model and embeddings
    embedding_model = load_embedding_model()
    embeddings_data = load_embeddings()
    
    # æ›´æ–°æ ‡é¢˜æ ·å¼
    st.markdown("""
    <h1 style='text-align: center; font-size: 18px; font-weight: bold;'>Medical Insights Copilot</h1>
    <h6 style='text-align: center; font-size: 12px;'>æ”¹å†™çš„ç»“æœåŠåé¦ˆå°†å‘ˆç°åœ¨ä¸‹æ–¹ï¼Œè¯·æ ¹æ®è‡ªå·±çš„åˆ¤æ–­è¿›è¡Œä½¿ç”¨</h6>
    <br><br><br>
    """, unsafe_allow_html=True)
    
    # Sidebar layout
    user_input = setup_sidebar(
        topics, primary_topics_list,
        institutions, departments, persons,
        generate_tag, generate_diseases_tag, rewrite,
        prob_identy, generate_structure_data,
        model_choice, client,
        embedding_model, embeddings_data
    )
    
    # Main page layout
    setup_main_page(
        model_choice, client, user_input
    )

def setup_sidebar(
    topics, primary_topics_list, institutions, departments, persons,
    generate_tag, generate_diseases_tag, rewrite,
    prob_identy, generate_structure_data,
    model_choice, client,
    embedding_model, embeddings_data
):
    with st.sidebar:
        st.markdown("""
        <div style="font-size:12px;">
        * Insightåº”æ¶µç›–4Wè¦ç´ ï¼ˆWho-è°ã€What-ä»€ä¹ˆã€Why-ä¸ºä»€ä¹ˆã€Wayfoward-æœªæ¥æ–¹å‘ï¼‰ã€‚<br>
        ä»¥ä¸‹æ˜¯ä¸€ä¸ªåˆæ ¼æ ·å¼çš„ç¤ºä¾‹ï¼š"ä¸€ä½{è„±æ•æœºæ„}çš„{ç§‘å®¤}çš„{è„±æ•äººç‰©}æŒ‡å‡º{è§‚ç‚¹}ï¼Œå¹¶é˜è¿°äº†{å†…å®¹é—´çš„é€»è¾‘è”ç³»}ï¼Œè¿›è€Œæå‡ºäº†{åç»­æ–¹æ¡ˆ}"ã€‚<br>
        * Insight Copilotï¼šæ‚¨å¯ä»¥åœ¨ä¸‹é¢æäº¤æ‚¨çš„åˆç¨¿æˆ–ä¸Šä¼ å›¾ç‰‡ï¼Œç„¶åä½¿æ­¤å·¥å…·å¯¹å†…å®¹è¿›è¡Œæ‰“æ ‡æˆ–è€…é‡å†™ã€‚æ‚¨è¿˜å¯ä»¥ç›´æ¥ä¿®æ”¹é‡å†™åçš„ç»“æœã€‚
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("<p style='font-size: 14px; font-weight: bold;'>Step 1: è¯·è¾“å…¥æ–‡å­—æˆ–ä¸Šä¼ å›¾ç‰‡ âœï¸:</p>", unsafe_allow_html=True)
        
        # åœ¨åˆ›å»ºæ–‡æœ¬æ¡†ä¹‹å‰æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…é™¤
        if "clear_clicked" not in st.session_state:
            st.session_state.clear_clicked = False
        
        # å¦‚æœæ¸…é™¤æŒ‰é’®è¢«ç‚¹å‡»ï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºçš„key
        if st.session_state.clear_clicked:
            key = "user_input_" + str(hash(time.time()))
            st.session_state.clear_clicked = False
        else:
            key = "user_input"

        # æ·»åŠ é€‰é¡¹å¡ç”¨äºæ–‡å­—è¾“å…¥å’Œå›¾ç‰‡ä¸Šä¼ 
        tab1, tab2 = st.tabs(["æ–‡å­—è¾“å…¥", "å›¾ç‰‡ä¸Šä¼ "])
        
        with tab1:
            # ä½¿ç”¨åŠ¨æ€keyåˆ›å»ºæ–‡æœ¬æ¡†
            user_input = st.text_area("", placeholder="è¯·è¾“å…¥å†…å®¹\næç¤ºï¼šæ‚¨å¯ä»¥æŒ‰ä¸‹ Ctrl + A å…¨é€‰å†…å®¹ï¼Œæ¥ç€æŒ‰ä¸‹ Ctrl + C å¤åˆ¶", key=key, height=200)
            
            # Find similar content when user inputs text
            if user_input and user_input.strip() != "":
                # Store in session state to avoid recalculating on every rerun
                if "similar_contents" not in st.session_state or st.session_state.get("last_input", "") != user_input:
                    with st.spinner("æ­£åœ¨æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹..."):
                        similar_contents = get_similar_content(user_input, embeddings_data, embedding_model,top_k = 5)
                        st.session_state.similar_contents = similar_contents
                        st.session_state.last_input = user_input

        with tab2:
            # åˆå§‹åŒ– session state
            if "previous_file_name" not in st.session_state:
                st.session_state.previous_file_name = None
                
            uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
            
            if uploaded_file is not None:
                current_file_name = uploaded_file.name
                
                # åªæœ‰å½“ä¸Šä¼ äº†æ–°æ–‡ä»¶æ—¶æ‰å¤„ç†å›¾ç‰‡
                if (st.session_state.previous_file_name != current_file_name):
                    image = Image.open(uploaded_file)
                    st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
                    
                    try:
                        with st.spinner('æ­£åœ¨å¤„ç†å›¾ç‰‡...'):
                            extracted_text = readimg(image)
                            st.session_state.extracted_text = extracted_text
                            st.session_state.previous_file_name = current_file_name
                            user_input = extracted_text
                            
                            # Find similar content for extracted text
                            similar_contents = get_similar_content(extracted_text, embeddings_data, embedding_model)
                            st.session_state.similar_contents = similar_contents
                            st.session_state.last_input = extracted_text
                    except Exception as e:
                        st.error(f"å›¾ç‰‡å¤„ç†å‡ºé”™: {str(e)}")
                        user_input = ""
                else:
                    # ä½¿ç”¨ç¼“å­˜çš„ç»“æœ
                    st.image(Image.open(uploaded_file), caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
                    user_input = st.session_state.extracted_text
                
                # æ˜¾ç¤ºæå–çš„æ–‡å­—
                st.text_area("æå–çš„æ–‡å­—", st.session_state.get("extracted_text", ""), height=200, key="extracted_text_display")

        # æ˜¾ç¤ºç›¸ä¼¼å†…å®¹
        # if "similar_contents" in st.session_state and st.session_state.similar_contents:
        #     with st.expander("ç›¸ä¼¼å†…å®¹ (Top 5)"):
        #         for i, item in enumerate(st.session_state.similar_contents):
        #             st.markdown(f"**ç›¸ä¼¼åº¦: {item['similarity']:.2f}**")
        #             st.markdown(f"```\n{item['content']}\n```")
        #             if i < len(st.session_state.similar_contents) - 1:
        #                 st.markdown("---")
        
        if "similar_contents" in st.session_state and st.session_state.similar_contents:
            with st.expander("ç›¸ä¼¼å†…å®¹ (Top 5)", expanded=True):
                # æ·»åŠ æ¯”è¾ƒç»“æœæ˜¾ç¤º
                if user_input and user_input.strip() != "":
                    api_key = os.environ.get("GROQ_API_KEY")
                    client = Groq(api_key=api_key)
                    comparison = generate_comparison(user_input, 'llama3-70b-8192', client, st.session_state.similar_contents)
                    st.markdown("### å†…å®¹æ¯”è¾ƒ")
                    st.markdown(comparison)
                    st.markdown("---")
                
                # åŸæœ‰çš„ç›¸ä¼¼å†…å®¹æ˜¾ç¤ºä»£ç 
                for i, item in enumerate(st.session_state.similar_contents):
                    col1, col2 = st.columns([1, 9])
                    with col1:
                        st.markdown(f"**{i+1}. {item['similarity']:.2f}**")
                        if 'timestamp' in item:
                            st.markdown(f"<small>{item['timestamp']}</small>", unsafe_allow_html=True)
                    with col2:
                        st.text_area(
                            label="",
                            value=item['content'],
                            height=100,
                            key=f"similar_content_{i}"
                        )
                    
                    if i < len(st.session_state.similar_contents) - 1:
                        st.markdown("<hr style='margin: 5px 0px'>", unsafe_allow_html=True)

        # if "similar_contents" in st.session_state and st.session_state.similar_contents:
        #     with st.expander("ç›¸ä¼¼å†…å®¹ (Top 5)", expanded=True):
        #         for i, item in enumerate(st.session_state.similar_contents):
        #             color = get_color(item['similarity'])
        #             with st.container():
        #                 col1, col2 = st.columns([2, 8])
        #                 with col1:
        #                     st.markdown(f"<h3 style='margin-bottom: 0; color: {color};'>{i+1}</h3>", unsafe_allow_html=True)
        #                     st.markdown(f"<p style='color: {color}; font-size: 0.9em; margin-top: 0; font-weight: bold;'>ç›¸ä¼¼åº¦: {item['similarity']:.2f}</p>", unsafe_allow_html=True)
        #                     if 'timestamp' in item:
        #                         st.markdown(f"<p style='color: #666; font-size: 0.8em;'>{item['timestamp']}</p>", unsafe_allow_html=True)
        #                 with col2:
        #                     st.markdown(
        #                         f"""
        #                         <div style='background-color: {color}22; border-left: 3px solid {color}; border-radius: 5px; padding: 10px; height: 100px; overflow-y: auto;'>
        #                             {item['content']}
        #                         </div>
        #                         """,
        #                         unsafe_allow_html=True
        #                     )
                        
        #                 if i < len(st.session_state.similar_contents) - 1:
        #                     st.markdown("<hr style='margin: 15px 0px; border: none; height: 1px; background-color: #e0e0e0;'>", unsafe_allow_html=True)
                
        # æ¸…é™¤æŒ‰é’®å¤„ç†
        with stylable_container(
            "clear_button",
            css_styles="""
            button {
                background-color: white;
                color: #7A00E6;
                border: 1px solid #7A00E6;
            }"""
        ):
            if st.button("ğŸ—‘ï¸ä¸€é”®æ¸…é™¤"):
                # æ¸…é™¤æ‰€æœ‰ç›¸å…³çš„ session state å˜é‡
                keys_to_clear = [
                    'previous_file_name', 
                    'extracted_text', 
                    'tags', 
                    'disease_tags', 
                    'rewrite_text', 
                    'table_df', 
                    'potential_issues',
                    'similar_contents',
                    'last_input'
                ]
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                st.session_state.clear_clicked = True
                st.rerun()
        
        st.markdown("<p style='font-size: 14px; font-weight: bold;'>Step 2: è¯·æ ¹æ®æ‹œè®¿é€‰æ‹©å¦‚ä¸‹ä¿¡æ¯ç”¨äºRewriteğŸ§‘â€âš•ï¸</p>", unsafe_allow_html=True)
        col1, col2, col3 = st.columns(3)
        with col1:
            st.session_state.institution = st.selectbox("Institution", institutions)
        with col2:
            st.session_state.department = st.selectbox("Department", departments)
        with col3:
            st.session_state.person = st.selectbox("Title", persons)

        col1, col2 = st.columns(2)
        with col1:
            with stylable_container("step1",
                    css_styles="""
                    button {
                        background-color: white;
                        color: #7A00E6;
                    }""",
                ):
                    if st.button("Generate Tags (Optional)"):
                        tags = generate_tag(user_input, model_choice, client)
                        unique_tags = list(set(tags.split(",")))
                        st.session_state.tags = ",".join(unique_tags)
            
                        disease_tags = generate_diseases_tag(user_input, model_choice, client)
                        unique_disease_tags = list(set(disease_tags.split(",")))
                        st.session_state.disease_tags = ",".join(unique_disease_tags)

        with col2:
            with stylable_container("step2",
                    css_styles="""
                    button {
                        background-color: #7A00E6;
                        color: white;
                    }""",
                    ):
                        if st.button("Rewrite   â†’", use_container_width=True):
                            process_rewrite(user_input, st.session_state.get('institution'), 
                                            st.session_state.get('department'), st.session_state.get('person'), 
                                            model_choice, client, rewrite, generate_structure_data, prob_identy)
        
    return user_input

def setup_main_page(
    model_choice, client, user_input
):
    display_tags()
    display_rewrite_results()

def display_tags():
    if 'tags' in st.session_state:
        user_generated_tags = re.split(r'[,\s]+', st.session_state.tags.strip())
        user_generated_tags = [tag for tag in user_generated_tags if tag]
        tag_html = " ".join([f'<span class="tag" style="background-color: {match_color(tag, colors, topics)};">{tag}</span>' for tag in user_generated_tags])
        st.markdown(f"**AutoTags:** {tag_html}", unsafe_allow_html=True)
        
        if 'disease_tags' in st.session_state:
            disease_tags = re.split(r'[,\s]+', st.session_state.disease_tags.strip())
            disease_tags = [tag for tag in disease_tags if tag]
            disease_tag_html = ", ".join(disease_tags)
            st.markdown(f"**Disease Tags:** {disease_tag_html}")

def process_rewrite(user_input, institution, department, person, model_choice, client,
                    rewrite, generate_structure_data, prob_identy):
    rewrite_text = rewrite(user_input, institution, department, person, model_choice, client)
    table_text = generate_structure_data(user_input, model_choice, client)
    
    try:
        st.session_state.table_df = json_to_dataframe(table_text)
    except Exception:
        # åªåœ¨ JSON è½¬æ¢å¤±è´¥æ—¶é™é»˜è®¾ç½®ä¸º None
        st.session_state.table_df = None   
        
    potential_issues = prob_identy(table_text, model_choice, client)
    st.session_state.rewrite_text = rewrite_text
    st.session_state.potential_issues = potential_issues

def display_rewrite_results():
    st.markdown("<p style='font-size: 14px; font-weight: bold;'>Editable Rewritten Text:</p>", unsafe_allow_html=True)

    if 'rewrite_text' in st.session_state:
        user_editable_text = st.text_area("", st.session_state.rewrite_text, height=300)
        st.session_state.rewrite_text = user_editable_text
    else:
        user_editable_text = st.text_area("", placeholder="Rewritten text will appear here after clicking 'Rewrite'\nTip: You can press Ctrl + A to select all the content, then press Ctrl + C to copy it\n\nContent quality may vary\nIf the result is not satisfactory, the 'Rewrite' button can be clicked again for a new attempt", height=300)

    with stylable_container(
        "copy_button",
        css_styles="""
        button {
            background-color: white;
            color: #7A00E6;
            border: 1px solid #7A00E6;
            padding: 5px 10px;
        }"""
    ):
        if st.button("ğŸ“‹ å¤åˆ¶"):
            if 'rewrite_text' in st.session_state:
                st.write("è¯·ç‚¹å‡»ä¸‹æ–¹å†…å®¹å³ä¸Šè§’è¿›è¡Œå¤åˆ¶ï¼")
                st.code(st.session_state.rewrite_text, language=None)
                st.toast("è¯·éµå¾ªä¸‹é¢æç¤ºè¿›è¡Œæ“ä½œï¼", icon="ğŸ˜„")
    
    if 'rewrite_text' in st.session_state:
        with st.expander("Assessment Feedback (click for details)"):
            background_color = determine_issue_severity(st.session_state.potential_issues)
            st.markdown(
                f"""
                <div style="background-color: {background_color}; color: black; padding: 10px; border-radius: 5px; font-family: sans-serif; font-size: 12px;">
                    {st.session_state.potential_issues}
                </div>
                """,
                unsafe_allow_html=True
            )
            
            if 'table_df' in st.session_state and st.session_state.table_df is not None:
                st.markdown("<p style='font-size: 12px; font-weight: bold;'>Extracted Information:</p>", unsafe_allow_html=True)
                st.dataframe(st.session_state.table_df)
            else:
                st.warning("No extracted information available.")

    st.markdown(
        """
        <style>
        .tag {
            display: inline-block;
            color: white;
            border-radius: 5px;
            padding: 5px;
            margin: 2px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

def generate_comparison(text, model_choice, client, similar_contents):
    """
    Generate comparison between user input and similar contents
    """
    # æ„å»ºçŸ¥è¯†åº“å†…å®¹å­—ç¬¦ä¸²
    knowledge_base = []
    for i, item in enumerate(similar_contents):
        knowledge_base.append(f"[{i+1}] {item['content']}")
    knowledge_base_str = "\n".join(knowledge_base)
    
    completion = client.chat.completions.create(
        model=model_choice,
        messages=[
            {
                "role": "system", 
                "content": """ä½ çš„èŒè´£æ˜¯æ¯”è¾ƒç”¨æˆ·çš„è¾“å…¥ï¼Œå’ŒçŸ¥è¯†åº“å†…å®¹çš„ç›¸ä¼¼æ€§å’Œä¸åŒï¼Œè¦æ ¹æ®å†…å®¹æœ¬èº«ï¼Œå°½é‡ä¸è¦å±•å¼€æ¨ç†ï¼Œè¾“å‡ºæ ¼å¼ï¼š
ç›¸ä¼¼è§‚ç‚¹ï¼šxxxx ï¼ˆç»™å‡ºå‡ºå¤„indexï¼‰
ä¸åŒè§‚ç‚¹ï¼šxxxxã€‚ï¼ˆç»™å‡ºå‡ºå¤„indexï¼‰

æ•´ä½“å°½é‡ç®€æ´ï¼Œå¦‚æœè§‚ç‚¹ä¸å­˜åœ¨ï¼Œç•™ä½ç©ºå³å¯"""
            },
            {
                "role": "user", 
                "content": f"ç”¨æˆ·è¾“å…¥ï¼š{text}\nçŸ¥è¯†åº“ï¼š{knowledge_base_str}"
            }
        ],
        temperature=0.1,
        max_tokens=1000,
    )
    summary = completion.choices[0].message.content.strip()
    return summary
