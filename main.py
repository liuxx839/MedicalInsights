#main.py
import streamlit as st
from layout import setup_layout
from functions import (
    setup_client, generate_tag, generate_diseases_tag, rewrite,
    prob_identy, generate_structure_data
)
from config import (
    topics, diseases, institutions, departments, persons,
    primary_topics_list, primary_diseases_list,colors
)
from streamlit_extras.stylable_container import stylable_container
import pandas as pd
import json
import time
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
from dagrelation import DAGRelations
from datadescription import DataDescription

def create_mermaid_html_from_edges(dag_edges):
    """
    Create a Mermaid flowchart HTML from a list of edges.
    
    Parameters:
    dag_edges (list): List of tuples representing edges. Each tuple can be:
                     - ('var1', 'var2') for a single edge
                     - (['var1', 'var2'], 'var3') for multiple sources to one target
    
    Returns:
    str: HTML code with embedded Mermaid flowchart
    """
    mermaid_code = ['flowchart TD']
    
    for edge in dag_edges:
        if isinstance(edge[0], list):
            # Handle multiple sources to one target
            source_vars = edge[0]
            target_var = edge[1]
            
            # Create individual connections for each source to target
            for source_var in source_vars:
                mermaid_code.append(f'    {source_var} --> {target_var}')
        else:
            # Simple one-to-one edge
            source_var = edge[0]
            target_var = edge[1]
            mermaid_code.append(f'    {source_var} --> {target_var}')
    
    # Join all lines with newlines
    mermaid_code_str = '\n'.join(mermaid_code)
    
    # Create the HTML with the embedded Mermaid code and zoom controls
    mermaid_html = f"""
<div id="mermaid-container" style="width:100%; height:100%; position:relative;">
    <div class="mermaid" id="mermaid-diagram">
    {mermaid_code_str}
    </div>
    
    <div style="position:absolute; top:10px; right:10px; background:white; padding:5px; border:1px solid #ccc; border-radius:5px;">
        <button onclick="zoomIn()" style="margin-right:5px;">â•</button>
        <button onclick="zoomOut()">â–</button>
        <button onclick="resetZoom()" style="margin-left:5px;">ğŸ”„</button>
    </div>
</div>

<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({{ startOnLoad: true }});
    
    window.currentZoom = 1;
    
    window.zoomIn = function() {{
        window.currentZoom += 0.1;
        document.getElementById('mermaid-diagram').style.transform = `scale(${{window.currentZoom}})`;
        document.getElementById('mermaid-diagram').style.transformOrigin = 'top left';
    }};
    
    window.zoomOut = function() {{
        if (window.currentZoom > 0.5) {{
            window.currentZoom -= 0.1;
            document.getElementById('mermaid-diagram').style.transform = `scale(${{window.currentZoom}})`;
            document.getElementById('mermaid-diagram').style.transformOrigin = 'top left';
        }}
    }};
    
    window.resetZoom = function() {{
        window.currentZoom = 1;
        document.getElementById('mermaid-diagram').style.transform = 'scale(1)';
    }};
</script>
"""
    
    return mermaid_html
    
def create_word_document(qa_response, fact_check_result=None):
    """
    åˆ›å»ºåŒ…å«QAå“åº”å’Œäº‹å®æ ¸æŸ¥ç»“æœçš„Wordæ–‡æ¡£ï¼Œæ”¯æŒMarkdownæ ‡é¢˜è½¬æ¢ä¸ºWordæ ·å¼
    """
    doc = Document()
    
    # è®¾ç½®æ ‡é¢˜
    title = doc.add_heading('Medical Knowledge Base Q&A Report', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # æ·»åŠ æ—¶é—´æˆ³
    timestamp = doc.add_paragraph()
    timestamp.add_run(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}").italic = True
    
    # æ·»åŠ QAå“åº”
    doc.add_heading('å›åº”å†…å®¹', level=1)
    
    # å¤„ç†QAå“åº”ä¸­çš„Markdownæ ¼å¼
    lines = qa_response.split('\n')
    current_text = []
    
    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œ
        if line.strip().startswith('#'):
            # å¦‚æœä¹‹å‰æœ‰ç´¯ç§¯çš„æ–‡æœ¬ï¼Œå…ˆæ·»åŠ ä¸ºæ®µè½
            if current_text:
                doc.add_paragraph(''.join(current_text))
                current_text = []
            
            # è®¡ç®—æ ‡é¢˜çº§åˆ«
            level = 1
            line = line.strip()
            while line.startswith('#'):
                level += 1
                line = line[1:]
            level = min(level, 9)  # Wordæ”¯æŒæœ€å¤š9çº§æ ‡é¢˜
            
            # ç§»é™¤å¯èƒ½çš„å¼•ç”¨æ ‡è®° [1,2,3] å¹¶ä¿å­˜
            citation = ''
            if '[' in line and ']' in line:
                main_text = line[:line.find('[')].strip()
                citation = line[line.find('['):].strip()
                heading = doc.add_heading(main_text, level=level-1)
                if citation:
                    heading.add_run(f" {citation}").italic = True
            else:
                doc.add_heading(line.strip(), level=level-1)
        else:
            current_text.append(line + '\n')
    
    # æ·»åŠ æœ€åå‰©ä½™çš„æ–‡æœ¬
    if current_text:
        doc.add_paragraph(''.join(current_text))
    
    # å¦‚æœæœ‰äº‹å®æ ¸æŸ¥ç»“æœï¼Œæ·»åŠ åˆ°æ–‡æ¡£
    if fact_check_result:
        doc.add_heading('äº‹å®æ ¸æŸ¥ç»“æœ', level=1)
        # å¯¹äº‹å®æ ¸æŸ¥ç»“æœä¹Ÿè¿›è¡Œç›¸åŒçš„å¤„ç†
        lines = fact_check_result.split('\n')
        current_text = []
        
        for line in lines:
            if line.strip().startswith('#'):
                if current_text:
                    doc.add_paragraph(''.join(current_text))
                    current_text = []
                
                level = 1
                line = line.strip()
                while line.startswith('#'):
                    level += 1
                    line = line[1:]
                level = min(level, 9)
                
                if '[' in line and ']' in line:
                    main_text = line[:line.find('[')].strip()
                    citation = line[line.find('['):].strip()
                    heading = doc.add_heading(main_text, level=level-1)
                    if citation:
                        heading.add_run(f" {citation}").italic = True
                else:
                    doc.add_heading(line.strip(), level=level-1)
            else:
                current_text.append(line + '\n')
        
        if current_text:
            doc.add_paragraph(''.join(current_text))
    
    # ä¿å­˜åˆ°å†…å­˜ä¸­
    doc_io = io.BytesIO()
    doc.save(doc_io)
    doc_io.seek(0)
    return doc_io

def extract_dag_edges(text_content):
    # ä»æ–‡æœ¬ä¸­æå– dag_edges éƒ¨åˆ†
    if "dag_edges = [" in text_content:
        start_idx = text_content.find("dag_edges = [")
        start_idx = text_content.find("[", start_idx)
        
        # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·
        open_brackets = 1
        end_idx = start_idx + 1
        
        while open_brackets > 0 and end_idx < len(text_content):
            if text_content[end_idx] == '[':
                open_brackets += 1
            elif text_content[end_idx] == ']':
                open_brackets -= 1
            end_idx += 1
        
        # æå– dag_edges åˆ—è¡¨å†…å®¹
        dag_edges_str = text_content[start_idx:end_idx]
        
        # ä½¿ç”¨ ast.literal_eval å®‰å…¨åœ°å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º Python å¯¹è±¡
        try:
            dag_edges = ast.literal_eval(dag_edges_str)
            return dag_edges
        except (SyntaxError, ValueError) as e:
            print(f"è§£æé”™è¯¯: {e}")
            return None
    
    return None

def setup_spreadsheet_analysis():
    st.markdown(
        """
    <h1 style='text-align: center; font-size: 18px; font-weight: bold;'>Spreadsheet Analysis</h1>
    <h6 style='text-align: center; font-size: 12px;'>ä¸Šä¼ Excel/CSVæ–‡ä»¶æˆ–ç²˜è´´JSONæ•°æ®è¿›è¡Œåˆ†æ</h6>
    <br><br><br>
    """,
        unsafe_allow_html=True,
    )
    
    # Initialize all session state variables
    if "analysis_response" not in st.session_state:
        st.session_state.analysis_response = ""
    if "analysis_reasoning" not in st.session_state:
        st.session_state.analysis_reasoning = ""
    if "dag_edges" not in st.session_state:
        st.session_state.dag_edges = ""
    if "sample_data" not in st.session_state:
        st.session_state.sample_data = {}
    if "business_report" not in st.session_state:
        st.session_state.business_report = ""
    if "dag_report" not in st.session_state:
        st.session_state.dag_report = ""
    if "dag_reasoning" not in st.session_state:
        st.session_state.dag_reasoning = ""
    if "df" not in st.session_state:
        st.session_state.df = None
    
    # Create tabs for different input methods
    tab1, tab2 = st.tabs(["æ–‡ä»¶ä¸Šä¼ ", "JSONç²˜è´´"])
    
    with tab1:
        uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶(xlsx/csv)", type=['xlsx', 'csv'])
        
        if uploaded_file is not None:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–æ•°æ®
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                # ä¿å­˜DataFrameåˆ°session state
                st.session_state.df = df
                
                # æ˜¾ç¤ºå‰10è¡Œæ•°æ®
                st.write("æ•°æ®é¢„è§ˆ:")
                st.dataframe(df)
                
                # ä¿å­˜sampleæ•°æ®åˆ°session state
                st.session_state.sample_data = df.head(10).to_dict()
                
            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    with tab2:
        json_input = st.text_area("ç²˜è´´JSONæ•°æ®:", height=200)
        process_json_button = st.button("å¤„ç†JSONæ•°æ®")
        
        if process_json_button and json_input:
            try:
                # æ¸…ç†JSONå­—ç¬¦ä¸² - å¦‚æœå‰åæœ‰é¢å¤–çš„å¼•å·ï¼Œå»æ‰å®ƒä»¬
                cleaned_json = json_input.strip()
                if cleaned_json.startswith('"') and cleaned_json.endswith('"'):
                    # å¦‚æœJSONè¢«é¢å¤–çš„å¼•å·åŒ…å›´ï¼Œå»æ‰è¿™äº›å¼•å·å¹¶å¤„ç†è½¬ä¹‰å­—ç¬¦
                    cleaned_json = cleaned_json[1:-1].replace('\\"', '"')
                
                # è§£æJSONæ•°æ®
                try:
                    json_data = json.loads(cleaned_json)
                    df = pd.DataFrame(json_data)
                except Exception as e:
                    # å¦‚æœç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•ä»¥Recordsæ ¼å¼è§£æ
                    try:
                        json_data = json.loads(cleaned_json)
                        if isinstance(json_data, list):
                            df = pd.DataFrame(json_data)
                        else:
                            df = pd.DataFrame([json_data])
                    except:
                        st.error(f"æ— æ³•è§£æJSONæ•°æ®: {str(e)}")
                        return
                
                # ä¿å­˜DataFrameåˆ°session state
                st.session_state.df = df
                
                # æ˜¾ç¤ºå‰10è¡Œæ•°æ®
                st.write("æ•°æ®é¢„è§ˆ:")
                st.dataframe(df)
                
                # ä¿å­˜sampleæ•°æ®åˆ°session state
                st.session_state.sample_data = df.head(10).to_dict()
                
            except Exception as e:
                st.error(f"å¤„ç†JSONæ•°æ®æ—¶å‡ºé”™: {str(e)}")
    
    # åªæœ‰å½“DataFrameå¯ç”¨æ—¶æ‰æ˜¾ç¤ºä¸‹é¢çš„æ§ä»¶
    if st.session_state.df is not None:
        # ç”¨æˆ·è¾“å…¥éœ€æ±‚
        user_question = st.text_area("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚:", height=100)
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä¸€åˆ—æ”¾ç”ŸæˆæŒ‰é’®ï¼Œä¸€åˆ—æ”¾DAGåˆ†ææŒ‰é’®
        col1, col2 = st.columns(2)
        
        with col1:
            # æ ¹æ®æ˜¯å¦å·²ç»è¿›è¡Œè¿‡DAGåˆ†ææ¥æ˜¾ç¤ºä¸åŒçš„æŒ‰é’®æ–‡æœ¬
            button_text = "å†æ¬¡ç”Ÿæˆ" if "business_report" in st.session_state and st.session_state.business_report else "ç”Ÿæˆ"
            generate_button = st.button(button_text)
        
        with col2:
            with stylable_container(
                "dag_analysis_button",
                css_styles="""
                    button {
                        background-color: #FFA500;
                        color: white;
                    }""",
            ):
                dag_analysis_button = st.button("ğŸ“Š DAGåˆ†æ")
        
        # ç¡®ä¿æœ‰DataFrameå¯ç”¨äºåˆ†æ
        df = st.session_state.df
        
        # å¤„ç†ç”ŸæˆæŒ‰é’®ç‚¹å‡»
        if generate_button and user_question:
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                # æ ¹æ®æ˜¯å¦å·²ç»æœ‰business_reportæ¥å†³å®šä½¿ç”¨å“ªä¸ªæç¤º
                if "business_report" in st.session_state and st.session_state.business_report:
                    # ä½¿ç”¨å·²æœ‰çš„business_reportä½œä¸ºè¾“å…¥ï¼Œé‡æ–°æ€è€ƒDAGç»“æ„
                    response = client_research.chat.completions.create(
                        model=model_choice_research,
                        messages=[
                            {
                                "role": "system",
                                "content": """ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„sampleæ•°æ®å’Œå·²æœ‰çš„åˆ†ææŠ¥å‘Šï¼Œé‡æ–°æ€è€ƒå¹¶ä¼˜åŒ–DAGå…³ç³»ã€‚
                                å…³æ³¨ä»¥ä¸‹å‡ ç‚¹ï¼š
                                1. ä»”ç»†åˆ†æå·²æœ‰æŠ¥å‘Šä¸­çš„å‘ç°å’Œå…³ç³»
                                2. é‡æ–°è¯„ä¼°å¯èƒ½çš„å› æœå…³ç³»
                                3. æ„å»ºæ›´ä¼˜åŒ–çš„DAGè¾¹
                                4. æ”¯æŒå¤šå¯¹ä¸€çš„å…³ç³»
                                5. ç¡®ä¿ä½¿ç”¨çš„æ˜¯åŸå§‹çš„åˆ—åï¼Œä¸è¦åšä»»ä½•ä¿®æ”¹
                                6. è€ƒè™‘å·²æœ‰åˆ†æä¸­å¯èƒ½è¢«å¿½ç•¥çš„å…³ç³»
                                7. ä¸è¦å¢åŠ ä»»ä½•ä¸å­˜åœ¨çš„åˆ—å

                                è¯·å…ˆæä¾›è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼Œç„¶åå†ç»™å‡ºä¼˜åŒ–åçš„DAGå®šä¹‰ã€‚

                                æœ€ç»ˆè¾“å‡ºæ ¼å¼å¿…é¡»å¦‚ä¸‹ï¼š
                                ##æ¨ç†è¿‡ç¨‹
                                [è¯¦ç»†çš„åˆ†ææ¨ç†è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¯¹å·²æœ‰åˆ†æçš„è¯„ä¼°]

                                ##å®šä¹‰DAGè¾¹ï¼ˆæ”¯æŒå¤šå¯¹ä¸€å…³ç³»ï¼‰
                                è¯·ä¸¥æ ¼éµå¾ªä¸‹é¢çš„æ ¼å¼ï¼Œä»”ç»†æ ¸å¯¹ï¼ŒåŠ¡å¿…ä¿è¯ä½¿ç”¨åŸå§‹åˆ—åï¼Œä»¥åŠæ­£ç¡®çš„æ‹¬å·
                                dag_edges = [
                                    ('var1', 'var2'),
                                    ('var3', 'var4'),
                                    # å¤šå¯¹ä¸€å…³ç³»ç¤ºä¾‹
                                    (['var1', 'var2'], 'var3'),
                                    (['var1', 'var2', 'var3'], 'var4')
                                ]
                                
                                ##åˆ†æè¯´æ˜ï¼š
                                [è¿™é‡Œæ˜¯å¯¹ä¼˜åŒ–åDAGç»“æ„çš„è§£é‡Šè¯´æ˜ï¼Œä»¥åŠä¸ä¹‹å‰åˆ†æçš„æ¯”è¾ƒ]
                                """
                            },
                            {
                                "role": "user",
                                "content": f"Sampleæ•°æ®ï¼š\n{st.session_state.sample_data}\n\nç”¨æˆ·éœ€æ±‚ï¼š{user_question}\n\nå·²æœ‰åˆ†ææŠ¥å‘Šï¼š\n{st.session_state.business_report}"
                            }
                        ],
                        temperature=0.7,
                        max_tokens=2000,
                        stream=True
                    )
                else:
                    # åŸæœ‰çš„æç¤ºï¼Œç”¨äºé¦–æ¬¡ç”Ÿæˆ
                    response = client_research.chat.completions.create(
                        model=model_choice_research,
                        messages=[
                            {
                                "role": "system", 
                                "content": """
                                ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„sampleæ•°æ®åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œå¹¶æ„å»ºæ½œåœ¨çš„DAGå…³ç³»ã€‚
                                å…³æ³¨ä»¥ä¸‹å‡ ç‚¹ï¼š
                                1. ä»”ç»†åˆ†ææ•°æ®åˆ—ä¹‹é—´çš„å…³ç³»
                                2. è¯†åˆ«å¯èƒ½çš„å› æœå…³ç³»
                                3. æ„å»ºåˆé€‚çš„DAGè¾¹
                                4. æ”¯æŒå¤šå¯¹ä¸€çš„å…³ç³»
                                5. ç¡®ä¿ä½¿ç”¨çš„æ˜¯åŸå§‹çš„åˆ—åï¼Œä¸è¦åšä»»ä½•ä¿®æ”¹
                                6. ä¸è¦å¢åŠ ä»»ä½•ä¸å­˜åœ¨çš„åˆ—å

                                æœ€ç»ˆè¾“å‡ºæ ¼å¼å¿…é¡»å¦‚ä¸‹ï¼š


                                ## å®šä¹‰DAGè¾¹ï¼ˆæ”¯æŒå¤šå¯¹ä¸€å…³ç³»ï¼‰
                                è¯·ä¸¥æ ¼éµå¾ªä¸‹é¢çš„æ ¼å¼ï¼Œä»”ç»†æ ¸å¯¹ï¼ŒåŠ¡å¿…ä¿è¯ä½¿ç”¨åŸå§‹åˆ—åï¼Œä»¥åŠæ­£ç¡®çš„æ‹¬å·
                                dag_edges = [
                                    ('var1', 'var2'),
                                    ('var3', 'var4'),
                                    # å¤šå¯¹ä¸€å…³ç³»ç¤ºä¾‹
                                    (['var1', 'var2'], 'var3'),
                                    (['var1', 'var2', 'var3'], 'var4')
                                ]


                                ## åˆ†æè¯´æ˜ï¼š
                                [è¿™é‡Œæ˜¯å¯¹DAGç»“æ„çš„è§£é‡Šè¯´æ˜ï¼ŒåŒ…å«åŸåˆ™éµå¾ªæƒ…å†µåˆ†æ]
                                """
                            },
                            {
                                "role": "user", 
                                "content": f"Sampleæ•°æ®ï¼š\n{st.session_state.sample_data}\n\nç”¨æˆ·éœ€æ±‚ï¼š{user_question}"
                            }
                        ],
                        temperature=0.7,
                        max_tokens=2000,
                        stream=True
                    )
                
                full_response = ""
                reasoning_content = ""
                
                # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºçš„å®¹å™¨
                progress_container = st.empty()
                
                # å¤„ç†æµå¼å“åº”
                for chunk in response:
                    if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                        reasoning_content += chunk.choices[0].delta.reasoning_content
                        progress_container.markdown(f"æ€è€ƒè¿‡ç¨‹ï¼š\n{reasoning_content}\n\nå›ç­”ï¼š\n{full_response}")
                    elif hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        progress_container.markdown(f"æ€è€ƒè¿‡ç¨‹ï¼š\n{reasoning_content}\n\nå›ç­”ï¼š\n{full_response}")
                
                # ä»…æå–DAGå®šä¹‰éƒ¨åˆ†
                dag_definition = ""
                if "dag_edges = [" in full_response:
                    dag_start = full_response.find("dag_edges = [")
                    
                    # Find the matching closing bracket by counting opening and closing brackets
                    open_brackets = 1
                    dag_end = dag_start + len("dag_edges = [")
                    
                    while open_brackets > 0 and dag_end < len(full_response):
                        if full_response[dag_end] == '[':
                            open_brackets += 1
                        elif full_response[dag_end] == ']':
                            open_brackets -= 1
                        dag_end += 1
                    
                    dag_definition = full_response[dag_start:dag_end]
                
                # ä¿å­˜åˆ°session state
                st.session_state.analysis_response = full_response
                st.session_state.analysis_reasoning = reasoning_content
                st.session_state.dag_edges = dag_definition
                
                # æ¸…ç©ºè¿›åº¦å®¹å™¨
                progress_container.empty()
        
        # å¤„ç†DAGåˆ†ææŒ‰é’®ç‚¹å‡»
        if dag_analysis_button and st.session_state.dag_edges:
            with st.spinner("æ­£åœ¨è¿›è¡ŒDAGåˆ†æ..."):
                try:
                    # æ‰§è¡ŒDAGåˆ†æ
                    dag_edges_text = st.session_state.dag_edges
                    dag_edges = extract_dag_edges(dag_edges_text)
                    
                    full_response = ""
                    reasoning_content = ""

                    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºçš„å®¹å™¨
                    dag_progress = st.empty()
                    
                    if dag_edges:
                        # æ‰§è¡ŒDAGåˆ†æ
                        analyzer = DAGRelations(df, dag_edges)
                        dag_report = analyzer.analyze_relations().print_report()
                        st.session_state.dag_report = dag_report

                        # æ·»åŠ æ•°æ®æè¿°åˆ†æ
                        data_analyzer = DataDescription(df, include_histogram=False, string_threshold=10)
                        data_analyzer.analyze_data()
                        json_output = data_analyzer.to_json()
                        st.session_state.data_description = json_output

                        # ç”Ÿæˆå•†ä¸šæŠ¥å‘Š
                        response = client_research.chat.completions.create(
                            model=model_choice_research,
                            messages=[
                                {
                                    "role": "system",
                                    "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„åˆå§‹åˆ†æç»“æœã€DAGåˆ†ææŠ¥å‘Šå’Œæ•°æ®æè¿°ä¿¡æ¯ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚å¦‚æœDAGåˆ†ææŠ¥å‘Šä¸å­˜åœ¨ï¼Œè¯·åœ¨æŠ¥å‘Šä¸­è¯´æ˜è¿™ä¸€æƒ…å†µã€‚

                                        æŠ¥å‘Šç»“æ„åº”åŒ…å«ï¼š

                                        # æ‰§è¡Œæ‘˜è¦
                                        ç®€æ˜æ‰¼è¦åœ°æ€»ç»“å…³é”®å‘ç°å’Œå»ºè®®ï¼ˆä¸è¶…è¿‡200å­—ï¼‰

                                        # æ•°æ®æ¦‚è§ˆ
                                        ## æ•°æ®åŸºæœ¬æƒ…å†µ
                                        ä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ï¼š
                                        | æ•°æ®ç»´åº¦ | å€¼ |
                                        | --- | --- |
                                        | æ€»è®°å½•æ•° | X |
                                        | å˜é‡æ•°é‡ | X |
                                        | æ•°å€¼å‹å˜é‡ | Xä¸ª (åˆ—å‡ºåç§°) |
                                        | åˆ†ç±»å‹å˜é‡ | Xä¸ª (åˆ—å‡ºåç§°) |
                                        | ç¼ºå¤±å€¼æƒ…å†µ | æ€»ä½“ç™¾åˆ†æ¯”åŠä¸»è¦ç¼ºå¤±åˆ— |

                                        ## å…³é”®å˜é‡åˆ†æ
                                        é’ˆå¯¹é‡è¦å˜é‡ä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ï¼š

                                        **æ•°å€¼å‹å˜é‡ç»Ÿè®¡**
                                        | å˜é‡å | å‡å€¼ | ä¸­ä½æ•° | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | å¼‚å¸¸å€¼æ¯”ä¾‹ |
                                        | --- | --- | --- | --- | --- | --- | --- |

                                        **åˆ†ç±»å‹å˜é‡ç»Ÿè®¡**
                                        | å˜é‡å | å”¯ä¸€å€¼æ•°é‡ | æœ€å¸¸è§ç±»åˆ«(å æ¯”) | ç†µå€¼(å½’ä¸€åŒ–) | åˆ†å¸ƒå‡è¡¡åº¦ |
                                        | --- | --- | --- | --- | --- | --- |

                                        # å˜é‡å…³ç³»åˆ†æ
                                        ## DAGå…³ç³»æ¦‚è¿°
                                        ä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ä¸»è¦å˜é‡é—´çš„å…³ç³»ï¼š

                                        | å…³ç³»ç±»å‹ | æºå˜é‡ | ç›®æ ‡å˜é‡ | ç»Ÿè®¡é‡ | på€¼ | æ˜¾è‘—æ€§ | å…³ç³»å¼ºåº¦ |
                                        | --- | --- | --- | --- | --- | --- | --- |

                                        ## è¯¦ç»†å…³ç³»åˆ†æ
                                        é’ˆå¯¹æ¯ä¸ªé‡è¦å…³ç³»ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

                                        ### å…³ç³»: [æºå˜é‡] -> [ç›®æ ‡å˜é‡]
                                        **ç»Ÿè®¡ç»“æœ:**
                                        - å…³ç³»ç±»å‹: [åˆ†ç±»->æ•°å€¼/æ•°å€¼->æ•°å€¼/åˆ†ç±»->åˆ†ç±»]
                                        - ç»Ÿè®¡é‡: [Få€¼/ç›¸å…³ç³»æ•°/å¡æ–¹å€¼] = X
                                        - på€¼: X
                                        - æ˜¾è‘—æ€§: [é«˜åº¦æ˜¾è‘—/æ˜¾è‘—/ä¸æ˜¾è‘—]

                                        **ç±»åˆ«ç»Ÿè®¡:** (é€‚ç”¨äºåˆ†ç±»->æ•°å€¼å…³ç³»)
                                        | ç±»åˆ« | æ ·æœ¬æ•° | å‡å€¼ | æ ‡å‡†å·® | ä¸æ€»ä½“å‡å€¼å·®å¼‚ |
                                        | --- | --- | --- | --- | --- |

                                        **æ˜¾è‘—å·®å¼‚ç±»åˆ«:**
                                        - ç±»åˆ«X: å‡å€¼Y (æ¯”æ€»ä½“å‡å€¼[é«˜/ä½]Z%)

                                        # å…³é”®æ´å¯Ÿ
                                        ## ä¸»è¦å‘ç°
                                        - å‘ç°1: [ç®€æ˜æè¿°] - æ”¯æŒæ•°æ®: [ç›¸å…³ç»Ÿè®¡ç»“æœ]
                                        - å‘ç°2: [ç®€æ˜æè¿°] - æ”¯æŒæ•°æ®: [ç›¸å…³ç»Ÿè®¡ç»“æœ]

                                        # æŠ€æœ¯é™„å½•
                                        ## DAGåˆ†æå®Œæ•´æŠ¥å‘Š
                                        [æ­¤å¤„ç›´æ¥æ’å…¥åŸå§‹DAGæŠ¥å‘Šï¼Œä¸åšä¿®æ”¹]

                                        è¯·ç¡®ä¿ï¼š
                                        1. è¡¨æ ¼æ ¼å¼æ¸…æ™°ï¼Œæ•°æ®å¯¹é½
                                        2. æ‰€æœ‰ç»Ÿè®¡ç»“æœä¿ç•™é€‚å½“å°æ•°ä½æ•°(é€šå¸¸2-4ä½)
                                        3. å¯¹ç»Ÿè®¡æ˜¾è‘—æ€§ä½¿ç”¨æ ‡å‡†è¡¨ç¤º: *** p<0.001, ** p<0.01, * p<0.05, ns pâ‰¥0.05
                                        4. å¯¹éæŠ€æœ¯è¯»è€…è§£é‡Šç»Ÿè®¡æœ¯è¯­ï¼Œä½†ä¿æŒä¸“ä¸šæ€§
                                        5. é‡ç‚¹çªå‡ºå¼‚å¸¸å€¼ã€æ˜¾è‘—å·®å¼‚å’Œæœ‰å•†ä¸šä»·å€¼çš„å‘ç°
                                        6. æ‰€æœ‰ç»“è®ºå¿…é¡»æœ‰æ•°æ®æ”¯æŒï¼Œé¿å…è¿‡åº¦è§£è¯»
                                        7. å¯¹äºå¤æ‚å…³ç³»ï¼Œæä¾›ç®€æ˜çš„è§£é‡Šå’Œå¯èƒ½çš„å› æœæœºåˆ¶
                                        8. è¯·æä¾›å°½å¯èƒ½è¯¦ç»†çš„æ•°æ®æ´å¯Ÿå’Œä¸šåŠ¡å½±å“åˆ†æ"""
                                },
                                {
                                    "role": "user",
                                    "content": f"""
                                    åˆå§‹åˆ†æç»“æœï¼š{st.session_state.analysis_response}
                                    DAGåˆ†ææŠ¥å‘Šï¼š{dag_report}
                                    æ•°æ®æè¿°ä¿¡æ¯ï¼š{json_output}
                                    
                                    è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ•°æ®åˆ†ææŠ¥å‘Šã€‚æŠ¥å‘Šåº”ä¸¥æ ¼éµå¾ªç³»ç»Ÿæç¤ºä¸­çš„ç»“æ„å’Œæ ¼å¼è¦æ±‚ï¼Œç‰¹åˆ«æ³¨æ„ï¼š
                                    1. å……åˆ†åˆ©ç”¨DAGåˆ†ææŠ¥å‘Šä¸­çš„ç»Ÿè®¡ç»“æœï¼ŒåŒ…æ‹¬Få€¼ã€på€¼å’Œç±»åˆ«ç»Ÿè®¡
                                    2. æ•´åˆæ•°æ®æè¿°ä¸­çš„ç»Ÿè®¡ä¿¡æ¯å’Œåˆ†å¸ƒç‰¹å¾
                                    3. æ‰€æœ‰è¡¨æ ¼å¿…é¡»æ ¼å¼è§„èŒƒï¼Œæ•°æ®å¯¹é½
                                    4. é‡ç‚¹å…³æ³¨ç»Ÿè®¡æ˜¾è‘—çš„å…³ç³»å’Œå¼‚å¸¸å€¼
                                    5. ç¡®ä¿éæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½ç†è§£æŠ¥å‘Šå†…å®¹
                                    6. æ‰€æœ‰ç»“è®ºå’Œå»ºè®®å¿…é¡»æœ‰æ•°æ®æ”¯æŒ
                                    """
                                }
                            ],
                            temperature=0.7,
                            max_tokens=5000,
                            stream=True
                        )
                        
                        full_response = ""
                        reasoning_content = ""
                        
                        # å¤„ç†æµå¼å“åº”
                        for chunk in response:
                            if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                                reasoning_content += chunk.choices[0].delta.reasoning_content
                                dag_progress.markdown(f"æ€è€ƒè¿‡ç¨‹ï¼š\n{reasoning_content}\n\nåˆ†æç»“æœï¼š\n{full_response}")
                            elif hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                                full_response += chunk.choices[0].delta.content
                                dag_progress.markdown(f"æ€è€ƒè¿‡ç¨‹ï¼š\n{reasoning_content}\n\nåˆ†æç»“æœï¼š\n{full_response}")
                        
                        # ä¿å­˜åˆ°session state
                        st.session_state.business_report = full_response + "\n\n# åˆ†æraw results\n" + dag_report + "\n\n# descriptive analysis\n" + json_output
                        st.session_state.dag_reasoning = reasoning_content
                        
                        # æ¸…ç©ºè¿›åº¦å®¹å™¨
                        dag_progress.empty()
                        
                except Exception as e:
                    st.error(f"DAGåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        
        # ä½¿ç”¨ä¸¤åˆ—æ˜¾ç¤ºåˆ†æç»“æœå’ŒDAGåˆ†æç»“æœ
        if st.session_state.analysis_response or st.session_state.business_report:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### æ•°æ®åˆ†æ")
                if st.session_state.analysis_reasoning:
                    with st.expander("æ€è€ƒè¿‡ç¨‹", expanded=False):
                        st.markdown(st.session_state.analysis_reasoning)
                st.markdown(st.session_state.analysis_response)
                
                # DAGå®šä¹‰ç¼–è¾‘å™¨
                st.markdown("### DAGå®šä¹‰")
                dag_editor = st.text_area("ç¼–è¾‘DAGè¾¹å®šä¹‰:", value=st.session_state.dag_edges, height=200)
                if dag_editor != st.session_state.dag_edges:
                    st.session_state.dag_edges = dag_editor
                # Generate the Mermaid HTML
                try:
                    # ç¡®ä¿å…ˆè§£ææ–‡æœ¬ä¸­çš„dag_edges
                    dag_edges = extract_dag_edges(st.session_state.dag_edges)
                    if dag_edges:
                        mermaid_html = create_mermaid_html_from_edges(dag_edges)
                        # æ¸²æŸ“ Mermaid å›¾ï¼Œå¹¶å¢åŠ é«˜åº¦ä»¥é€‚åº”ç¼©æ”¾
                        st.markdown("## å…³ç³»å›¾ (ä½¿ç”¨å³ä¸Šè§’æŒ‰é’®ç¼©æ”¾)")
                        st.components.v1.html(mermaid_html, height=600, scrolling=True)
                    else:
                        st.warning("æ— æ³•è§£æDAGè¾¹å®šä¹‰ï¼Œè¯·æ£€æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¡®")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå…³ç³»å›¾æ—¶å‡ºé”™: {str(e)}")
            
            with col2:
                if st.session_state.business_report:
                    st.markdown("### DAGåˆ†æç»“æœ")
                    if hasattr(st.session_state, 'dag_reasoning'):
                        with st.expander("åˆ†æè¿‡ç¨‹", expanded=False):
                            st.markdown(st.session_state.dag_reasoning)
                    st.markdown(st.session_state.business_report)
            
            # æ·»åŠ ä¸‹è½½æŒ‰é’®
            if st.session_state.business_report:
                st.markdown("---")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š",
                    data=create_word_document(st.session_state.business_report),
                    file_name=f"data_analysis_report_{time.strftime('%Y%m%d_%H%M%S')}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
                
def main():
    st.set_page_config(layout="wide")
    
    model_choice, client = setup_client()
    # Create the page selection in sidebar
    page = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", ["Medical Insights Copilot", "Spreadsheet Analysis"])
    
    if page == "Medical Insights Copilot":  
        setup_layout(
            topics, diseases, institutions, departments, persons,
            primary_topics_list, primary_diseases_list,
            generate_tag, generate_diseases_tag, rewrite,
            prob_identy, generate_structure_data,
            model_choice, client
        )
    elif page == "Spreadsheet Analysis":
            setup_spreadsheet_analysis()


if __name__ == "__main__":
    main()
